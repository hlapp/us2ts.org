---
layout: page
title: Hybrid AI for Context Understanding
author: Maulik R. Kamdar
permalink: program-hybrid-ai
mainnav: false
sidenav: false
published: true
order: 5
---

#### Session Organizers
- Alessandro Oltramari, Bosch Research and Technology Center (Pittsburgh, PA) 
- Cory Henson, Bosch Research and Technology Center (Pittsburgh, PA) 
- Ruwan Wickramarachchi, AI Institute, University of South Carolina (Columbia, SC) 

#### Abstract 
Context understanding can be conceived as the capability of making sense of a broad range of situations, e.g. a particular arrangement of cars and pedestrians on a city intersection, a conversation during a customer service call, a retreat of troops from a battlefield, etc. 

By making sense of the environment, as humans we learned to survive in the wilderness, escaping predators, enduring natural catastrophes, epidemics, and overcoming the intrinsic limitations of our own species. Through sensory stimuli, humans accumulate experiences, generalize and reason over them, storing the resulting knowledge in memory; the dynamic combination of live experience and distilled knowledge during task execution, enables humans to make time effective decisions, evaluating how good or bad a decision was by factoring external feedback in. 

But if assessing situations and act consequentially evolved into a robust feature of human intelligence, the construction of a computational model of context understanding represents a long-standing challenge for artificial intelligence. Endowing machines with sense-making capability is not only a key requirement for improving their autonomy but, in first place, is a precondition for enabling seamless interaction with humans. In fact, humans communicate efficiently thanks to their shared mental models of the physical and social context: not only these models foster reciprocal trust by making contextual knowledge transparent, but are also crucial to explain how decision making unfolds. 

In our presentation we aim to illustrate two concrete scenarios of context-understanding realized by neuro-symbolic architectures, namely hybrid AI frameworks that integrate machine learning and machine-processable knowledge. The presentation is tied to two projects undergoing in Bosch, respectively focused on understanding traffic scenes for autonomous vehicles, and endowing customer-service chatbots with common sense knowledge. 

We would like to structure the session as follows: 
- Presentation (60 minutes) 
- Questions, comments, discussion (30 minutes) 

**Topics:** Semantic Technologies, Deep Learning, Cognitive Science, Natural Language Understanding, Internet of Things. Verticals: autonomous driving, smart assistance. 

**Type of session:** Presentations 

**Expected participation:** 
We’d expect participants from academia and industry. 
The interest in approaches that integrate data-driven AI and knowledge-based AI is growing, as events like the AAAI-MAKE symposium and Semantic Deep Learning workshop show – just to name two recent event series. As the short description above suggests, our presentations don’t only focus on the application side of the problem, but stem from a theoretical framework where the definition of context understanding is inspired by cognitive science, philosophy, linguistics. In this regard, we anticipate attendance from scholars with an interest in the general aspects of neuro-symbolic approaches, as well as from practitioners with an interest in the industrial nature of our research projects (e.g., scalability, deployment, lesson learned, etc.). We’d also welcome people with an interest in sharing their experience in other fields (e.g., defense applications), as part of the discussion. 